---
title: "One Shot Word Learning Analysis"
output: html_notebook
---

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(stringr)
```

# Data Loading

```{r}
#words = c("explained", "bonuses", "explained_2nd", "bonuses_2nd") #, "bonuses", "entry", "rice", "rolled", "marketers", "immune", "cowboys", "borrow")
#num_train = 1:10
#approaches = c("opt", "opt_centroid", "centroid", "opt_zero")

#d = data.frame()
#for (word in words) {
#  for (n in num_train) {
#    for (a in approaches) {
#      filename = sprintf("../%s/%i_%s_results_log.csv", word, n, a)
#      this_d = read.csv(filename, header=F)
#      this_d = this_d %>% 
#        spread(V1, V2) %>%
#        mutate(new_word=word, num_train=n, approach=a)
#      d = rbind(d, this_d)
#      
#    }
#  }
#}
```

# Data manipulation
```{r}
#d = d %>% mutate(nw_delta = post_new_word_test_perp - pre_new_word_test_perp, ptb_test_delta=post_test_perp - pre_test_perp)
```

# Centroid vs. optimizing

```{r, warning=F, message=F}
#ggplot(data=d, aes(x=num_train, y=nw_delta, color=approach)) +
#  geom_line() +
#  facet_wrap(~ new_word) +
#  xlab("Number of training sentences") +
#  scale_x_continuous(breaks=1:10) +
#  ylab("Change in perplexity on new word dataset") +
#  theme_bw()
```

```{r}
#ggsave('../results/first_run_bonuses_vs_explained.png')
```

# Better comparison: 10 perms w/ fixed test


```{r}
words = c("explained", "bonuses", "strategist") 
num_train = 1:10
perms = 1:10
approaches = c("opt", "opt_centroid", "centroid", "opt_zero")

d = data.frame()
withword_d = data.frame()
for (word in words) {
  for (perm in perms) {
    for (n in num_train) {
      for (a in approaches) {
        filename = sprintf("../result_data/%s_perm%i_train_logs/%s/%i_%s_results_log.csv", word, perm, word, n, a)
        this_d = read.csv(filename, header=F)
        this_d = this_d %>% 
          spread(V1, V2) %>%
          mutate(new_word=word, perm=perm, num_train=n, approach=a)
        d = rbind(d, this_d)
        
      }
    }
  }
  filename = sprintf("../result_data/%s_withword_train_logs/%s/_results_log.csv", word, word)
  this_d2 = read.csv(filename, header=F)
  this_d2 = this_d2 %>% 
    spread(V1, V2) %>%
    mutate(new_word=word) %>%
    select(-post_new_word_test_perp) %>%
    rename(post_withword_test_perp = pre_new_word_test_perp) %>%
    mutate(withoutword_test_perp=head(this_d$pre_new_word_test_perp, n=1))
  withword_d = rbind(withword_d, this_d2)
}

```

# Data manipulation
```{r}
d = d %>% mutate(nw_delta = post_new_word_test_perp - pre_new_word_test_perp, perm=factor(perm)) #, ptb_test_delta=post_test_perp - pre_test_perp)
withword_d = withword_d %>% mutate(nw_delta = post_withword_test_perp - withoutword_test_perp)
```

```{r}
number_of_new_words = length(words)
withword_d = withword_d[rep(1:number_of_new_words, each=10),]
withword_d = withword_d %>%
  mutate(num_train=rep(1:10, number_of_new_words),approach='train with word') %>%
  select(num_train, approach, new_word, nw_delta)
avg_d = d %>% 
  group_by(num_train, approach, new_word) %>% 
  summarize(nw_delta = mean(nw_delta)) %>% 
  ungroup() %>% 
  rbind(., withword_d)
```

# Approach comparisons

```{r, echo=FALSE, message=F}
ggplot() +
  geom_line(data=avg_d, aes(x=num_train, y=nw_delta, color=approach)) +
  geom_line(data=d, aes(x=num_train,y=nw_delta, color=approach, group=interaction(approach, perm)), alpha=0.15) +
  facet_wrap(~ new_word) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=1:10) +
  scale_color_brewer(palette='Dark2') +
  ylab("Change in perplexity on new word dataset") +
  theme_bw()
```
```{r}
ggsave('../results/10perms_delta_perplexity.png')
```


# Embeddings


(moved to python for efficiency)
```{r}
#words = c("explained", "bonuses") 
#num_train = 1:10
#perms = 1:10
#approaches = c("opt_centroid", "centroid", "opt_zero")

#d_emb = data.frame()
#for (word in words) {
#  for (a in approaches) {
#    for (perm in perms) {
#      for (n in num_train) {
#      
#        filename = sprintf("../result_data/%s_perm%i_train_logs/%s/embedding/num%i_%s_embedding_%s.csv", word, perm, word, n, a, a)
#        this_d = read.csv(filename, header=F)
#        this_d = this_d %>% 
#          mutate(index=1:1500) %>%
#          spread(index, V1) %>%
#          mutate(new_word=word, perm=perm, num_train=n, approach=a)
#        d_emb = rbind(d_emb, this_d)
#      }
#    }
#  }
#}
```


```{r}
#library(proxy)
```


```{r}
#q = simil(d_emb %>% select(-c(new_word, perm, num_train, approach)), upper=T, by_rows=T)
#image(as.matrix(q))
```


(moved to python for efficiency)
```{r}
#filename = sprintf("../result_data/pre_embeddings/%s/embedding_pre_full.csv", 'bonuses')
#full_pre_emb = read.csv(filename, header=F)
```
```{r}
#centroid = full_pre_emb %>% summarize_all(mean)
```





# Embeddings for real


```{r}
approaches = c("centroid", "opt", "opt_centroid", "opt_zero")

embedding_d = data.frame()
softmax_weight_d = data.frame()
this_d = read.csv('intermediate_data/emb_other_simils.csv', header=F)
this_d = this_d %>% 
  mutate(type='Other words') %>%
  rename(euclidean_distance=V1)
embedding_d = rbind(embedding_d, this_d)
this_d = read.csv('intermediate_data/smw_other_simils.csv', header=F)
this_d = this_d %>% 
  mutate(type='Other words') %>%
  rename(euclidean_distance=V1)
softmax_weight_d = rbind(softmax_weight_d, this_d)
for (a in 1:4) {
  for (b in a:4) {
    this_type = sprintf('%s vs. %s', approaches[a], approaches[b])
    this_d = read.csv(sprintf('intermediate_data/emb_%s_%s_simils.csv', approaches[a], approaches[b]), header=F)
    this_d = this_d %>% 
      mutate(type=this_type) %>%
      rename(euclidean_distance=V1)
    embedding_d = rbind(embedding_d, this_d)
    this_d = read.csv(sprintf('intermediate_data/smw_%s_%s_simils.csv', approaches[a], approaches[b]), header=F)
    this_d = this_d %>% 
      mutate(type=this_type) %>%
      rename(euclidean_distance=V1)
    softmax_weight_d = rbind(softmax_weight_d, this_d)
  }
}
```


```{r}
ggplot(data=embedding_d, aes(x=type, y=euclidean_distance, fill=type)) +
  geom_violin() +
  guides(fill=F) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggsave('../results/emb_distances_violin.png')


ggplot(data=softmax_weight_d, aes(x=type, y=euclidean_distance, fill=type)) +
  geom_violin() +
  guides(fill=F) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggsave('../results/smw_distances_violin.png')
```



# Optimizing only input or output embeddings

```{r}
words = c("explained", "bonuses", "strategist", "marketers") 
num_train = c(1, 10)
perms = 1:10
approaches = c("opt_centroid", "centroid")
skips = c("emb","sm")

skip_d = data.frame()
for (word in words) {
  for (perm in perms) {
    for (skipping in skips) {
      for (n in num_train) {
        for (a in approaches) {
          filename = sprintf("../result_data/%s_perm%i_skipping_%s_train_logs/%s/%i_%s_results_log.csv", word, perm, skipping, word, n, a)
          this_d = read.csv(filename, header=F)
          this_d = this_d %>% 
            spread(V1, V2) %>%
            mutate(new_word=word, perm=perm, num_train=n, approach=a, skipping=skipping)
          skip_d = rbind(skip_d, this_d)
        }
      }
    }
  }
}
```

```{r}
skip_d = skip_d %>% mutate(nw_delta = post_new_word_test_perp - pre_new_word_test_perp,
                           perm=factor(perm),
                           optimizing=ifelse(skipping=="None", "both", ifelse(skipping == "sm", "emb", "sm"))) 
```

```{r}
# combine with subset of full training data that matches
filtered_d = d %>% 
  filter(num_train %in% c(1, 10), 
         approach %in% approaches) %>%
  mutate(skipping='None', optimizing='both')
skip_d = rbind(filtered_d, skip_d)
```

```{r}
avg_skip_d = skip_d %>% 
  group_by(num_train, approach, new_word, optimizing) %>% 
  summarize(nw_delta = mean(nw_delta)) %>% 
  ungroup()
```

# Approach comparisons

```{r, echo=FALSE, message=F}
ggplot() +
  geom_line(data=avg_skip_d, aes(x=num_train, y=nw_delta, color=optimizing)) +
  geom_line(data=skip_d, aes(x=num_train, y=nw_delta, color=optimizing, group=interaction(optimizing, perm)), alpha=0.15) +
  facet_grid(approach ~ new_word) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=10) +
  scale_fill_brewer(palette='Dark2') +
  ylab("Change in perplexity on new word dataset") +
  theme_bw()
```

```{r}
noword_avg_skip_d = skip_d %>% 
  group_by(num_train, approach, optimizing) %>% 
  summarize(nw_delta = mean(nw_delta)) %>% 
  ungroup()
```

```{r}
ggplot() +
  geom_line(data=noword_avg_skip_d, aes(x=num_train, y=nw_delta, color=optimizing)) +
  facet_grid(~ approach) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=10) +
  scale_color_brewer(palette='Dark2') +
  ylab("Change in perplexity on new word dataset") +
  theme_bw()
```

