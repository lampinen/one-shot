---
title: "One Shot Word Learning Analysis"
output: html_notebook
---

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(stringr)
```

# Data Loading

```{r}
#words = c("explained", "bonuses", "explained_2nd", "bonuses_2nd") #, "bonuses", "entry", "rice", "rolled", "marketers", "immune", "cowboys", "borrow")
#num_train = 1:10
#Approaches = c("opt", "opt_centroid", "centroid", "opt_zero")

#d = data.frame()
#for (word in words) {
#  for (n in num_train) {
#    for (a in Approaches) {
#      filename = sprintf("../%s/%i_%s_results_log.csv", word, n, a)
#      this_d = read.csv(filename, header=F)
#      this_d = this_d %>% 
#        spread(V1, V2) %>%
#        mutate(new_word=word, num_train=n, Approach=a)
#      d = rbind(d, this_d)
#      
#    }
#  }
#}
```

# Data manipulation
```{r}
#d = d %>% mutate(nw_delta = post_new_word_test_perp - pre_new_word_test_perp, ptb_test_delta=post_test_perp - pre_test_perp)
```

# Centroid vs. optimizing

```{r, warning=F, message=F}
#ggplot(data=d, aes(x=num_train, y=nw_delta, color=Approach)) +
#  geom_line() +
#  facet_wrap(~ new_word) +
#  xlab("Number of training sentences") +
#  scale_x_continuous(breaks=1:10) +
#  ylab("Change in perplexity on new word dataset") +
#  theme_bw()
```

```{r}
#ggsave('../results/first_run_bonuses_vs_explained.png')
```

# Better comparison: 10 perms w/ fixed test


```{r}
words = c("explained", "bonuses", "strategist", "marketers") 
num_train = 1:10
perms = 1:10
Approaches = c("opt", "opt_centroid", "centroid", "opt_zero")

d = data.frame()
withword_d = data.frame()
for (word in words) {
  for (perm in perms) {
    for (n in num_train) {
      for (a in Approaches) {
        filename = sprintf("../result_data/%s_perm%i_train_logs/%s/%i_%s_results_log.csv", word, perm, word, n, a)
        if (!file.exists(filename)) {
          next
        }
        this_d = read.csv(filename, header=F)
        this_d = this_d %>% 
          spread(V1, V2) %>%
          mutate(new_word=word, perm=perm, num_train=n, Approach=a)
        d = bind_rows(d, this_d)
        
      }
    }
  }
  filename = sprintf("../result_data/%s_withword_train_logs/%s/_results_log.csv", word, word)
  if (!file.exists(filename)) {
    next
  }
  this_d2 = read.csv(filename, header=F)
  this_d2 = this_d2 %>% 
    spread(V1, V2) %>%
    mutate(new_word=word) %>%
    select(-post_new_word_test_perp) %>%
    rename(post_withword_test_perp = pre_new_word_test_perp) %>%
    mutate(withoutword_test_perp=head(this_d$pre_new_word_test_perp, n=1))
  withword_d = bind_rows(withword_d, this_d2)
}

```

# Data manipulation
```{r}
d = d %>% 
  mutate(nw_delta = post_new_word_test_perp - pre_new_word_test_perp, pct_delta=100*nw_delta/pre_new_word_test_perp, perm=factor(perm), train_with_word=F) %>%
  mutate(Approach=factor(Approach, 
                         levels=c("centroid", "opt", "opt_centroid", "opt_zero", "train_with_word"), 
                         labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word")))
withword_d = withword_d %>% mutate(nw_delta = post_withword_test_perp - withoutword_test_perp, pct_delta=100*nw_delta/withoutword_test_perp)
```

```{r}
number_of_new_words = length(words)
withword_d = withword_d[rep(1:number_of_new_words, each=10),]
withword_d = withword_d %>%
  mutate(num_train=rep(1:10, number_of_new_words), Approach='Full training\nwith the word', train_with_word=T) %>%
  select(num_train, Approach, new_word, nw_delta, pct_delta, train_with_word)
avg_d = d %>% 
  group_by(num_train, Approach, new_word, train_with_word) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta=mean(pct_delta)) %>% 
  ungroup() %>% 
  rbind(., withword_d) %>%
  mutate(Approach=factor(Approach, 
                         levels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word"), 
                         labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word")))
```

# Approach comparisons

```{r, echo=FALSE, message=F}
ggplot() +
  geom_line(data=avg_d, aes(x=num_train, y=pct_delta, color=Approach, linetype=train_with_word), size=1) +
  geom_line(data=d, aes(x=num_train,y=pct_delta, color=Approach, group=interaction(Approach, perm)), alpha=0.25) +
  facet_wrap(~ new_word) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=1:10) +
  scale_color_brewer(palette='Dark2') +
  ylab("Change in perplexity on new word test data (%)") +
  guides(linetype=F) +
  theme_bw(base_size=12) +
  guides(color=guide_legend(
                 keywidth=0.1,
                 keyheight=0.4,
                 default.unit="inch"))+
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```
```{r}
ggsave('../results/10perms_delta_perplexity.png', width=7, height=5)
```

```{r}
noword_withword_d = withword_d %>%
  group_by(num_train, Approach, train_with_word) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta=mean(pct_delta)) %>% 
  ungroup()
noword_d = d %>% 
  group_by(num_train, Approach, train_with_word) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta=mean(pct_delta)) %>% 
  ungroup() %>%
  bind_rows(., noword_withword_d) %>%
  mutate(Approach=factor(Approach, 
                         levels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word"), 
                         labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word")))
```

```{r, echo=FALSE, message=F}
ggplot() +
  geom_line(data=noword_d, aes(x=num_train, y=pct_delta, color=Approach, linetype=train_with_word), size=1) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=1:10) +
  scale_color_brewer(palette='Dark2') +
  ylab("Change in perplexity on new word test data (%)") +
  guides(linetype=F) +
  theme_bw(base_size=12) +
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```
```{r}
ggsave('../results/10perms_delta_perplexity_summarized.png', width=10, height=7)
```
# Embeddings


(moved to python for efficiency)
```{r}
#words = c("explained", "bonuses") 
#num_train = 1:10
#perms = 1:10
#Approaches = c("opt_centroid", "centroid", "opt_zero")

#d_emb = data.frame()
#for (word in words) {
#  for (a in Approaches) {
#    for (perm in perms) {
#      for (n in num_train) {
#      
#        filename = sprintf("../result_data/%s_perm%i_train_logs/%s/embedding/num%i_%s_embedding_%s.csv", word, perm, word, n, a, a)
#        this_d = read.csv(filename, header=F)
#        this_d = this_d %>% 
#          mutate(index=1:1500) %>%
#          spread(index, V1) %>%
#          mutate(new_word=word, perm=perm, num_train=n, Approach=a)
#        d_emb = rbind(d_emb, this_d)
#      }
#    }
#  }
#}
```


```{r}
#library(proxy)
```


```{r}
#q = simil(d_emb %>% select(-c(new_word, perm, num_train, Approach)), upper=T, by_rows=T)
#image(as.matrix(q))
```


(moved to python for efficiency)
```{r}
#filename = sprintf("../result_data/pre_embeddings/%s/embedding_pre_full.csv", 'bonuses')
#full_pre_emb = read.csv(filename, header=F)
```
```{r}
#centroid = full_pre_emb %>% summarize_all(mean)
```





# Embeddings for real


```{r}
Approaches = c("centroid", "opt", "opt_centroid", "opt_zero")

embedding_d = data.frame()
softmax_weight_d = data.frame()
this_d = read.csv('intermediate_data/emb_other_simils.csv', header=F)
this_d = this_d %>% 
  mutate(type='Other words') %>%
  rename(euclidean_distance=V1)
embedding_d = rbind(embedding_d, this_d)
this_d = read.csv('intermediate_data/smw_other_simils.csv', header=F)
this_d = this_d %>% 
  mutate(type='Other words') %>%
  rename(euclidean_distance=V1)
softmax_weight_d = rbind(softmax_weight_d, this_d)
for (a in 1:4) {
  for (b in a:4) {
    this_type = sprintf('%s vs. %s', Approaches[a], Approaches[b])
    this_d = read.csv(sprintf('intermediate_data/emb_%s_%s_simils.csv', Approaches[a], Approaches[b]), header=F)
    this_d = this_d %>% 
      mutate(type=this_type) %>%
      rename(euclidean_distance=V1)
    embedding_d = rbind(embedding_d, this_d)
    this_d = read.csv(sprintf('intermediate_data/smw_%s_%s_simils.csv', Approaches[a], Approaches[b]), header=F)
    this_d = this_d %>% 
      mutate(type=this_type) %>%
      rename(euclidean_distance=V1)
    softmax_weight_d = rbind(softmax_weight_d, this_d)
  }
}
```


```{r}
ggplot(data=embedding_d, aes(x=type, y=euclidean_distance, fill=type)) +
  geom_violin() +
  guides(fill=F) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggsave('../results/emb_distances_violin.png')


ggplot(data=softmax_weight_d, aes(x=type, y=euclidean_distance, fill=type)) +
  geom_violin() +
  guides(fill=F) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggsave('../results/smw_distances_violin.png')
```



# Optimizing only input or output embeddings

```{r}
words = c("explained", "bonuses", "strategist", "marketers") 
num_train = c(1, 10)
perms = 1:10
Approaches = c("opt_centroid", "centroid")
skips = c("emb","sm")

skip_d = data.frame()
for (word in words) {
  for (perm in perms) {
    for (skipping in skips) {
      for (n in num_train) {
        for (a in Approaches) {
          filename = sprintf("../result_data/%s_perm%i_skipping_%s_train_logs/%s/%i_%s_results_log.csv", word, perm, skipping, word, n, a)
          if (!file.exists(filename)){
            next
          }
          this_d = read.csv(filename, header=F)
          this_d = this_d %>% 
            spread(V1, V2) %>%
            mutate(new_word=word, perm=perm, num_train=n, Approach=a, skipping=skipping)
          skip_d = bind_rows(skip_d, this_d)
        }
      }
    }
  }
}
```

```{r}
skip_d = skip_d %>% mutate(nw_delta = post_new_word_test_perp - pre_new_word_test_perp,
                           pct_delta = 100 * nw_delta / pre_new_word_test_perp,
                           perm=factor(perm),
                           Optimizing=ifelse(skipping=="None", "Both", ifelse(skipping == "sm", "Input Embedding", "Output Embedding")),
                           Approach=factor(Approach, 
                                           levels=c("centroid", "opt", "opt_centroid", "opt_zero", "train_with_word"), 
                                           labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word")))
```

```{r}
# combine with subset of full training data that matches
filtered_d = d %>% 
  filter(num_train %in% c(1, 10), 
         Approach %in% c("Centroid", "Optimizing\nfrom centroid")) %>%
  mutate(skipping='None', Optimizing='Both') %>%
  select(-train_with_word)
skip_d = rbind(filtered_d, skip_d)
skip_d = skip_d %>%
  mutate(Optimizing=factor(Optimizing, levels=c("Input Embedding", "Output Embedding", "Both"))) %>%
  mutate(Approach=factor(Approach, 
                         levels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word"), 
                         labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word")))
```

```{r}
avg_skip_d = skip_d %>% 
  group_by(num_train, Approach, new_word, Optimizing) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta = mean(pct_delta)) %>% 
  ungroup()
```

# Approach comparisons

```{r, echo=FALSE, message=F}
ggplot() +
  geom_line(data=avg_skip_d, aes(x=num_train, y=pct_delta, color=Optimizing), size=1) +
  geom_line(data=skip_d, aes(x=num_train, y=pct_delta, color=Optimizing, group=interaction(Optimizing, perm)), alpha=0.25) +
  facet_grid(Approach ~ new_word) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=c(1,10)) +
  scale_color_manual(values= c("#377EB8", "#E41A1C", "#984EA3")) +
  ylab("Change in perplexity on new word test data (%)") +
  theme_bw(base_size=12)
```

```{r}
ggsave('../results/skipping_by_word.png', width=7, height=5)
```

```{r}
noword_avg_skip_d = skip_d %>% 
  group_by(num_train, Approach, Optimizing) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta = mean(pct_delta)) %>% 
  ungroup()
```

```{r}
ggplot() +
  geom_line(data=noword_avg_skip_d, aes(x=num_train, y=pct_delta, color=Optimizing), size=1) +
  facet_grid(~ Approach) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=c(1,10)) +
  scale_color_brewer(palette='Dark2') +
  ylab("Change in perplexity on new word test data (%)") +
  theme_bw(base_size=12)
```

```{r}
ggsave('../results/skipping_summarized.png')
```


# Round 2


```{r}
words = c("borrow", "cowboys", "immune", "rice") 
num_train = 1:10
perms = 1:10
Approaches = c("opt_centroid", "centroid")

d = data.frame()
withword_d = data.frame()
for (word in words) {
  for (perm in perms) {
    for (n in num_train) {
      for (a in Approaches) {
        filename = sprintf("../result_data_3/%s_perm%i_train_logs/%s/%i_%s_results_log.csv", word, perm, word, n, a)
        if (!file.exists(filename)) {
          next
        }
        this_d = read.csv(filename, header=F)
        this_d = this_d %>% 
          spread(V1, V2) %>%
          mutate(new_word=word, perm=perm, num_train=n, Approach=a)
        d = bind_rows(d, this_d)
        
      }
    }
  }
  filename = sprintf("../result_data_3/%s_withword_train_logs/%s/_results_log.csv", word, word)
  if (!file.exists(filename)) {
    next
  }
  this_d2 = read.csv(filename, header=F)
  this_d2 = this_d2 %>% 
    spread(V1, V2) %>%
    mutate(new_word=word) %>%
    select(-post_new_word_test_perp) %>%
    rename(post_withword_test_perp = pre_new_word_test_perp) %>%
    mutate(withoutword_test_perp=head(this_d$pre_new_word_test_perp, n=1), without_test_perp=head(this_d$pre_test_perp, n=1))
  withword_d = bind_rows(withword_d, this_d2)
}

```

# Data manipulation
```{r}
d = d %>% 
  mutate(nw_delta = post_new_word_test_perp - pre_new_word_test_perp, pct_delta=100*nw_delta/pre_new_word_test_perp, test_delta=post_test_perp - pre_test_perp, pct_test_delta = 100 * test_delta/pre_test_perp, perm=factor(perm), train_with_word=F) %>%
  mutate(Approach=factor(Approach, 
                         levels=c("centroid", "opt", "opt_centroid", "opt_zero", "train_with_word"), 
                         labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word")))
withword_d = withword_d %>% mutate(nw_delta = post_withword_test_perp - withoutword_test_perp,  pct_delta=100*nw_delta/withoutword_test_perp, test_delta=post_test_perp - without_test_perp, pct_test_delta = 100 * test_delta/pre_test_perp)
```

```{r}
number_of_new_words = length(words)
withword_d = withword_d[rep(1:number_of_new_words, each=10),]
withword_d = withword_d %>%
  mutate(num_train=rep(1:10, number_of_new_words), Approach='Full training\nwith the word', train_with_word=T) %>%
  select(num_train, Approach, new_word, nw_delta, pct_delta, test_delta, pct_test_delta, train_with_word)
avg_d = d %>% 
  group_by(num_train, Approach, new_word, train_with_word) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta=mean(pct_delta), test_delta=mean(test_delta), pct_test_delta=mean(pct_test_delta)) %>% 
  ungroup() %>% 
  rbind(., withword_d) %>%
  mutate(Approach=factor(Approach, 
                         levels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word"), 
                         labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word")))
```

# Approach comparisons

```{r, echo=FALSE, message=F}
ggplot() +
  geom_line(data=avg_d, aes(x=num_train, y=pct_delta, color=Approach, linetype=train_with_word), size=1) +
  geom_line(data=d, aes(x=num_train,y=pct_delta, color=Approach, group=interaction(Approach, perm)), alpha=0.25) +
  facet_wrap(~ new_word) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=1:10) +
  scale_color_brewer(palette='Dark2', drop=FALSE) +
  ylab("Change in perplexity on new word test data (%)") +
  guides(linetype=F,
         color=guide_legend(
                 keywidth=0.1,
                 keyheight=0.4,
                 default.unit="inch"))+
  theme_bw(base_size=12) +
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```
```{r}
ggsave('../results/10perms2_delta_perplexity.png', width=7, height=5)
```

```{r}
ggplot() +
  geom_line(data=avg_d, aes(x=num_train, y=pct_test_delta, color=Approach, linetype=train_with_word), size=1) +
  geom_line(data=d, aes(x=num_train,y=pct_test_delta, color=Approach, group=interaction(Approach, perm)), alpha=0.25) +
  facet_wrap(~ new_word) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=1:10) +
  scale_color_brewer(palette='Dark2', drop=F) +
  ylab("Change in perplexity on PTB test data (%)") +
  guides(linetype=F,
         color=guide_legend(
                 keywidth=0.1,
                 keyheight=0.4,
                 default.unit="inch"))+
  theme_bw(base_size=12) +
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```

```{r}
ggsave('../results/10perms2_cost_to_others.png', width=7, height=5)
```

# Round 3 - leave bias at centroid


```{r}
words = c("borrow", "cowboys", "immune", "rice") 
num_train = 1:10
perms = 1:10
Approaches = c("opt_centroid", "centroid")

d = data.frame()
withword_d = data.frame()
for (word in words) {
  for (perm in perms) {
    for (n in num_train) {
      for (a in Approaches) {
        filename = sprintf("../result_data_4/%s_perm%i_train_logs/%s/%i_%s_results_log.csv", word, perm, word, n, a)
        if (!file.exists(filename)) {
          next
        }
        this_d = read.csv(filename, header=F)
        this_d = this_d %>% 
          spread(V1, V2) %>%
          mutate(new_word=word, perm=perm, num_train=n, Approach=a)
        d = bind_rows(d, this_d)
        
      }
    }
  }
  filename = sprintf("../result_data_3/%s_withword_train_logs/%s/_results_log.csv", word, word) #3 is intentional -- no need to train again
  if (!file.exists(filename)) {
    next
  }
  this_d2 = read.csv(filename, header=F)
  this_d2 = this_d2 %>% 
    spread(V1, V2) %>%
    mutate(new_word=word) %>%
    select(-post_new_word_test_perp) %>%
    rename(post_withword_test_perp = pre_new_word_test_perp) %>%
    mutate(withoutword_test_perp=head(this_d$pre_new_word_test_perp, n=1), without_test_perp=head(this_d$pre_test_perp, n=1))
  withword_d = bind_rows(withword_d, this_d2)
}

```

# Data manipulation
```{r}
d = d %>% 
  mutate(nw_delta = post_new_word_test_perp - pre_new_word_test_perp, pct_delta=100*nw_delta/pre_new_word_test_perp, test_delta=post_test_perp - pre_test_perp, pct_test_delta = 100 * test_delta/pre_test_perp, perm=factor(perm), train_with_word=F) %>%
  mutate(Approach=factor(Approach, 
                         levels=c("centroid", "opt", "opt_centroid", "opt_zero", "train_with_word"), 
                         labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word")))
withword_d = withword_d %>% mutate(nw_delta = post_withword_test_perp - withoutword_test_perp,  pct_delta=100*nw_delta/withoutword_test_perp, test_delta=post_test_perp - without_test_perp, pct_test_delta = 100 * test_delta/pre_test_perp)
```

```{r}
number_of_new_words = length(words)
withword_d = withword_d[rep(1:number_of_new_words, each=10),]
withword_d = withword_d %>%
  mutate(num_train=rep(1:10, number_of_new_words), Approach='Full training\nwith the word', train_with_word=T) %>%
  select(num_train, Approach, new_word, nw_delta, pct_delta, test_delta, pct_test_delta, train_with_word)
avg_d = d %>% 
  group_by(num_train, Approach, new_word, train_with_word) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta=mean(pct_delta), test_delta=mean(test_delta), pct_test_delta=mean(pct_test_delta)) %>% 
  ungroup() %>% 
  rbind(., withword_d) %>%
  mutate(Approach=factor(Approach, 
                         levels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word"), 
                         labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word")))
```

# Approach comparisons

```{r, echo=FALSE, message=F}
ggplot() +
  geom_line(data=avg_d, aes(x=num_train, y=pct_delta, color=Approach, linetype=train_with_word), size=1) +
  geom_line(data=d, aes(x=num_train,y=pct_delta, color=Approach, group=interaction(Approach, perm)), alpha=0.25) +
  facet_wrap(~ new_word) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=1:10) +
  scale_color_brewer(palette='Dark2', drop=FALSE) +
  ylab("Change in perplexity on new word test data (%)") +
  guides(linetype=F,
         color=guide_legend(
                 keywidth=0.1,
                 keyheight=0.4,
                 default.unit="inch"))+
  theme_bw(base_size=12) +
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```
```{r}
ggsave('../results/10perms4_bias_cent_delta_perplexity.png', width=7, height=5)
```

```{r}
ggplot() +
  geom_line(data=avg_d, aes(x=num_train, y=pct_test_delta, color=Approach, linetype=train_with_word), size=1) +
  geom_line(data=d, aes(x=num_train,y=pct_test_delta, color=Approach, group=interaction(Approach, perm)), alpha=0.25) +
  facet_wrap(~ new_word) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=1:10) +
  scale_color_brewer(palette='Dark2', drop=F) +
  ylab("Change in perplexity on PTB test data (%)") +
  guides(linetype=F,
         color=guide_legend(
                 keywidth=0.1,
                 keyheight=0.4,
                 default.unit="inch"))+
  theme_bw(base_size=12) +
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```

```{r}
ggsave('../results/10perms4_bias_cent_cost_to_others.png', width=7, height=5)
```

# Round 4 - include replay


```{r}
words = c("borrow", "cowboys", "immune", "rice") 
num_train = 1:10
perms = 1:2
Approaches = c("opt_centroid", "centroid")

d = data.frame()
withword_d = data.frame()
for (word in words) {
  for (perm in perms) {
    for (n in num_train) {
      for (a in Approaches) {
        filename = sprintf("../result_data_5/%s_perm%i_train_logs/%s/%i_%s_results_log.csv", word, perm, word, n, a)
        if (!file.exists(filename)) {
          next
        }
        this_d = read.csv(filename, header=F)
        this_d = this_d %>% 
          spread(V1, V2) %>%
          mutate(new_word=word, perm=perm, num_train=n, Approach=a)
        d = bind_rows(d, this_d)
        
      }
    }
  }
  filename = sprintf("../result_data_3/%s_withword_train_logs/%s/_results_log.csv", word, word) #3 is intentional -- no need to train again
  if (!file.exists(filename)) {
    next
  }
  this_d2 = read.csv(filename, header=F)
  this_d2 = this_d2 %>% 
    spread(V1, V2) %>%
    mutate(new_word=word) %>%
    select(-post_new_word_test_perp) %>%
    rename(post_withword_test_perp = pre_new_word_test_perp) %>%
    mutate(withoutword_test_perp=head(this_d$pre_new_word_test_perp, n=1), without_test_perp=head(this_d$pre_test_perp, n=1))
  withword_d = bind_rows(withword_d, this_d2)
}

```

# Data manipulation
```{r}
d = d %>% 
  mutate(nw_delta = post_new_word_test_perp - pre_new_word_test_perp, pct_delta=100*nw_delta/pre_new_word_test_perp, test_delta=post_test_perp - pre_test_perp, pct_test_delta = 100 * test_delta/pre_test_perp, perm=factor(perm), train_with_word=F) %>%
  mutate(Approach=factor(Approach, 
                         levels=c("centroid", "opt", "opt_centroid", "opt_zero", "train_with_word"), 
                         labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word")))
withword_d = withword_d %>% mutate(nw_delta = post_withword_test_perp - withoutword_test_perp,  pct_delta=100*nw_delta/withoutword_test_perp, test_delta=post_test_perp - without_test_perp, pct_test_delta = 100 * test_delta/pre_test_perp)
```

```{r}
number_of_new_words = length(words)
withword_d = withword_d[rep(1:number_of_new_words, each=10),]
withword_d = withword_d %>%
  mutate(num_train=rep(1:10, number_of_new_words), Approach='Full training\nwith the word', train_with_word=T) %>%
  select(num_train, Approach, new_word, nw_delta, pct_delta, test_delta, pct_test_delta, train_with_word)
avg_d = d %>% 
  group_by(num_train, Approach, new_word, train_with_word) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta=mean(pct_delta), test_delta=mean(test_delta), pct_test_delta=mean(pct_test_delta)) %>% 
  ungroup() %>% 
  rbind(., withword_d) %>%
  mutate(Approach=factor(Approach, 
                         levels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word"), 
                         labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word")))
```

# Approach comparisons

```{r, echo=FALSE, message=F}
ggplot() +
  geom_line(data=avg_d, aes(x=num_train, y=pct_delta, color=Approach, linetype=train_with_word), size=1) +
  geom_line(data=d, aes(x=num_train,y=pct_delta, color=Approach, group=interaction(Approach, perm)), alpha=0.25) +
  facet_wrap(~ new_word) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=1:10) +
  scale_color_brewer(palette='Dark2', drop=FALSE) +
  ylab("Change in perplexity on new word test data (%)") +
  guides(linetype=F,
         color=guide_legend(
                 keywidth=0.1,
                 keyheight=0.4,
                 default.unit="inch"))+
  theme_bw(base_size=12) +
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```
```{r}
ggsave('../results/10perms5_replay_delta_perplexity.png', width=7, height=5)
```

```{r}
ggplot() +
  geom_line(data=avg_d, aes(x=num_train, y=pct_test_delta, color=Approach, linetype=train_with_word), size=1) +
  geom_line(data=d, aes(x=num_train,y=pct_test_delta, color=Approach, group=interaction(Approach, perm)), alpha=0.25) +
  facet_wrap(~ new_word) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=1:10) +
  ylim(NA, 2.0) +
  scale_color_brewer(palette='Dark2', drop=F) +
  ylab("Change in perplexity on PTB test data (%)") +
  guides(linetype=F,
         color=guide_legend(
                 keywidth=0.1,
                 keyheight=0.4,
                 default.unit="inch"))+
  theme_bw(base_size=12) +
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```

```{r}
ggsave('../results/10perms5_replay_cost_to_others.png', width=7, height=5)
```

# Embeddings 2.0
```{r}
smw_d = read.csv('../result_data_4/simil_corrs.csv', header=T)

smw_d = smw_d %>% 
  mutate(similarity_correlation = 1-similarity_correlation) %>% #correlation instead of correlation distance -- easier to read
  group_by(word, approach, perm, num_train) %>%
  summarize(similarity_correlation = mean(similarity_correlation)) %>%
  ungroup() %>%
  mutate(approach=factor(approach, 
                         levels=c(" centroid", "Optimizing\nfrom current", " opt_centroid", "Optimizing\nfrom zero", " with"), 
                         labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word"))) 

smw_withword_d = smw_d %>%
  filter(approach == "Full training\nwith the word")

smw_withword_d = smw_withword_d[rep(1:4, each=10),] %>%
  mutate(num_train = rep(1:10, 4)) %>%
  select(-perm) %>%
  mutate(train_with_word=T)

smw_d = smw_d %>%
  filter(approach != "Full training\nwith the word") %>%
  mutate(train_with_word=F)
```


```{r}
avg_d = smw_d  %>%
  filter(approach != 'with') %>%
  group_by(word, approach, num_train, train_with_word) %>%
  summarize(similarity_correlation = mean(similarity_correlation)) %>%
  ungroup %>%
  bind_rows(smw_withword_d)

ggplot(data=smw_d) +
  geom_line(aes(x=num_train, y=similarity_correlation, color=approach, group=interaction(approach, perm)), alpha=0.25) +
  geom_line(data=avg_d, aes(x=num_train, y=similarity_correlation, color=approach, linetype=train_with_word), size=1) +
  facet_wrap( ~ word) +
  labs(x="Number of training sentences", y = "Similarity structure correlation", color = "Approach") +
  scale_x_continuous(breaks=1:10) +
  ylim(-1, 1) +
  scale_color_brewer(palette='Dark2', drop=F) +
  guides(linetype=F,
         color=guide_legend(
                 keywidth=0.1,
                 keyheight=0.4,
                 default.unit="inch"))+
  theme_bw(base_size=12) +
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```
```{r}
ggsave('../results/10perms4_similarity_correlations.png', width=7, height=5)
```

```{r}
smw_within_d = read.csv('../result_data_4/within_simil_corrs.csv', header=T) %>%
  mutate(similarity_correlation = 1 - similarity_correlation)  # corr. dist. -> correlation
```
```{r}
smw_withword_d %>%
  summarize(similarity_correlation=mean(similarity_correlation))

smw_within_d %>%
  group_by(approach, num_train) %>%
  summarize(similarity_correlation=mean(similarity_correlation))
```



# Round 6 - final for submission, more replay


```{r}
words = c("borrow", "cowboys", "immune", "rice") 
num_train = 1:10
perms = 1:5
Approaches = c("opt_centroid", "centroid")

d = data.frame()
withword_d = data.frame()
for (word in words) {
  for (perm in perms) {
    for (n in num_train) {
      for (a in Approaches) {
        filename = sprintf("../result_data_6/%s_perm%i_train_logs/%s/%i_%s_results_log.csv", word, perm, word, n, a)
        if (!file.exists(filename)) {
          next
        }
        this_d = read.csv(filename, header=F)
        this_d = this_d %>% 
          spread(V1, V2) %>%
          mutate(new_word=word, perm=perm, num_train=n, Approach=a)
        d = bind_rows(d, this_d)
        
      }
    }
  }
  filename = sprintf("../result_data_3/%s_withword_train_logs/%s/_results_log.csv", word, word) #3 is intentional -- no need to train again
  if (!file.exists(filename)) {
    next
  }
  this_d2 = read.csv(filename, header=F)
  this_d2 = this_d2 %>% 
    spread(V1, V2) %>%
    mutate(new_word=word) %>%
    select(-post_new_word_test_perp) %>%
    rename(post_withword_test_perp = pre_new_word_test_perp) %>%
    mutate(withoutword_test_perp=head(this_d$pre_new_word_test_perp, n=1), without_test_perp=head(this_d$pre_test_perp, n=1))
  withword_d = bind_rows(withword_d, this_d2)
}

```

# Data manipulation
```{r}
d = d %>% 
  filter(!is.na(post_new_word_test_perp)) %>%
  mutate(nw_delta = post_new_word_test_perp - pre_new_word_test_perp, pct_delta=100*nw_delta/pre_new_word_test_perp, test_delta=post_test_perp - pre_test_perp, pct_test_delta = 100 * test_delta/pre_test_perp, perm=factor(perm), train_with_word=F) %>%
  mutate(Approach=factor(Approach, 
                         levels=c("centroid", "opt", "opt_centroid", "opt_zero", "train_with_word"), 
                         labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word")))
withword_d = withword_d %>% 
  mutate(nw_delta = post_withword_test_perp - withoutword_test_perp,  pct_delta=100*nw_delta/withoutword_test_perp, test_delta=post_test_perp - without_test_perp, pct_test_delta = 100 * test_delta/pre_test_perp)
```

```{r}
number_of_new_words = length(words)
withword_d = withword_d[rep(1:number_of_new_words, each=10),]
withword_d = withword_d %>%
  mutate(num_train=rep(1:10, number_of_new_words), Approach='Full training\nwith the word', train_with_word=T) %>%
  select(num_train, Approach, new_word, nw_delta, pct_delta, test_delta, pct_test_delta, train_with_word)
avg_d = d %>% 
  group_by(num_train, Approach, new_word, train_with_word) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta=mean(pct_delta), test_delta=mean(test_delta), pct_test_delta=mean(pct_test_delta)) %>% 
  ungroup() %>% 
  rbind(., withword_d) %>%
  mutate(Approach=factor(Approach, 
                         levels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word"), 
                         labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith the word")))
```

# Approach comparisons

```{r, echo=FALSE, message=F}
ggplot() +
  geom_line(data=avg_d, aes(x=num_train, y=pct_delta, color=Approach, linetype=train_with_word, group=Approach), size=1) +
  geom_line(data=d, aes(x=num_train,y=pct_delta, color=Approach, group=interaction(Approach, perm)), alpha=0.25) +
  facet_wrap(~ new_word) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=1:10) +
  scale_color_brewer(palette='Dark2', drop=FALSE) +
  ylab("Change in perplexity on new word test data (%)") +
  guides(linetype=F,
         color=guide_legend(
                 keywidth=0.1,
                 keyheight=0.4,
                 default.unit="inch"))+
  theme_bw(base_size=12) +
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```
```{r}
ggsave('../results/10perms6_replay_delta_perplexity.png', width=7, height=5)
```

```{r}
ggplot() +
  geom_line(data=avg_d, aes(x=num_train, y=pct_test_delta, color=Approach, linetype=train_with_word), size=1) +
  geom_line(data=d, aes(x=num_train,y=pct_test_delta, color=Approach, group=interaction(Approach, perm)), alpha=0.25) +
  facet_wrap(~ new_word) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=1:10) +
  ylim(NA, 2.0) +
  scale_color_brewer(palette='Dark2', drop=F) +
  ylab("Change in perplexity on PTB test data (%)") +
  guides(linetype=F,
         color=guide_legend(
                 keywidth=0.1,
                 keyheight=0.4,
                 default.unit="inch"))+
  theme_bw(base_size=12) +
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```

```{r}
ggsave('../results/10perms6_replay_cost_to_others.png', width=7, height=5)
```

```{r}
d %>%
  group_by(Approach, num_train) %>%
  summarize(max_delta=max(pct_test_delta), max_nw_delta = min(pct_delta))
```

# Hundred words

```{r}
words = c('ab', 'absolutely', 'agricultural', 'aim', 'animals', 'announcing', 'arguments', 'assist', 'averaged', 'bass', 'bullish', 'calculations', 'carefully', 'claiming', 'compare', 'conceded', 'congressman', 'consortium', 'contest', 'creation', 'cumulative', 'danger', 'darman', 'die', 'discrimination', 'disney', 'dominant', 'dorrance', 'edwards', 'efficiency', 'elderly', 'enable', 'encouraging', 'entry', 'environmentalists', 'execution', 'expenditures', 'facts', 'formula', 'gaf', 'geneva', 'globe', 'golf', 'healthcare', 'homeless', 'honor', 'horse', 'incest', 'informed', 'investigators', 'iron', 'jackson', 'judgment', 'knight', 'lake', 'lend', 'louisville', 'lowest', 'lucrative', 'maturing', 'minute', 'mississippi', 'motorola', 'museum', 'nabisco', 'netherlands', 'nigel', 'nine-month', 'owning', 'petrochemical', 'pioneer', 'prepare', 'print', 'pro-choice', 'recognized', 'referred', 'regarded', 'rejection', 'requests', 'resorts', 'responsibilities', 'rolled', 'sansui', 'serving', 'setback', 'similarly', 'somewhere', 'sounds', 'staffers', 'stolen', 'treasurys', 'treat', 'truth', 'utah', 'vulnerable', 'ward', 'warsaw', 'wedtech', 'wheat', 'wisconsin') 

Approaches = c("opt_centroid", "centroid")

d = data.frame()
withword_d = data.frame()
for (word in words) {
      for (a in Approaches) {
        filename = sprintf("../result_data_hundred/%s/%s_results_log.csv", word, a)
        if (!file.exists(filename)) {
          next
        }
        this_d = read.csv(filename, header=F)
        this_d = this_d %>% 
          spread(V1, V2) %>%
          mutate(new_word=word, Approach=a)
        d = bind_rows(d, this_d)
        
      }
  filename = sprintf("../result_data_hundred/with_hundred_words/%s/withword_results_log.csv", word, word) 
  if (!file.exists(filename)) {
    next
  }
  this_d2 = read.csv(filename, header=F)
  this_d2 = this_d2 %>% 
    spread(V1, V2) %>%
    mutate(new_word=word) %>%
    select(-post_new_word_test_perp) %>%
    rename(post_withword_test_perp = pre_new_word_test_perp) %>%
    mutate(withoutword_test_perp=head(this_d$pre_new_word_test_perp, n=1), without_test_perp=head(this_d$pre_test_perp, n=1))
  withword_d = bind_rows(withword_d, this_d2)
}

```

# Data manipulation
```{r}
d = d %>% 
  filter(!is.na(post_new_word_test_perp)) %>%
  mutate(nw_delta = post_new_word_test_perp - pre_new_word_test_perp, pct_delta=100*nw_delta/pre_new_word_test_perp, test_delta=post_test_perp - pre_test_perp, pct_test_delta = 100 * test_delta/pre_test_perp,  train_with_word=F) %>%
  mutate(Approach=factor(Approach, 
                         levels=c("centroid", "opt", "opt_centroid", "opt_zero", "train_with_word"), 
                         labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith all words")))
withword_d = withword_d %>% 
  mutate(nw_delta = post_withword_test_perp - withoutword_test_perp,  pct_delta=100*nw_delta/withoutword_test_perp, test_delta=post_test_perp - without_test_perp, pct_test_delta = 100 * test_delta/pre_test_perp)
```

```{r}
number_of_new_words = length(words)
withword_d = withword_d %>%
  mutate(Approach='Full training\nwith all words', train_with_word=T) %>%
  select(Approach, new_word, nw_delta, pct_delta, test_delta, pct_test_delta, train_with_word)
avg_withword_d = withword_d %>% 
  group_by(Approach, train_with_word) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta=mean(pct_delta), test_delta=mean(test_delta), pct_test_delta=mean(pct_test_delta)) %>% 
  ungroup() 
avg_d = d %>% 
  group_by(Approach, train_with_word) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta=mean(pct_delta), test_delta=mean(test_delta), pct_test_delta=mean(pct_test_delta)) %>% 
  ungroup() %>% 
  rbind(., avg_withword_d) %>%
  mutate(Approach=factor(Approach, 
                         levels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith all words"), 
                         labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith all words")))

```

```{r}
plotting_d = d %>%
  select(Approach, new_word,nw_delta,pct_delta,test_delta,pct_test_delta,train_with_word) %>%
  rbind(., withword_d) %>%
  mutate(Approach=factor(Approach, 
                         levels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith all words"), 
                         labels=c("Centroid", "Optimizing\nfrom current", "Optimizing\nfrom centroid", "Optimizing\nfrom zero", "Full training\nwith all words")))
```

# Approach comparisons

```{r, echo=FALSE, message=F}
ggplot() +
  geom_point(data=avg_d, aes(x=Approach, y=pct_delta, color=Approach), stat="identity", size = 5) +
  geom_point(data=plotting_d, aes(x=Approach,y=pct_delta, color=Approach), position=position_jitter(height=0., width=0.2), alpha=0.2) +
  scale_color_brewer(palette='Dark2', drop=FALSE) +
  ylab("Change in perplexity on new word test data (%)") +
  guides(linetype=F,
         color=F)+
  theme_bw(base_size=12) +
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```
```{r}
ggsave('../results/hundred_replay_delta_perplexity.png', width=7, height=5)
```

```{r}
ggplot() +
  geom_point(data=avg_d, aes(x=Approach, y=pct_test_delta, color=Approach), stat="identity", size = 5) +
  geom_point(data=plotting_d %>% filter(!grepl("Full", Approach)), aes(x=Approach,y=pct_test_delta, color=Approach), position=position_jitter(height=0., width=0.2), alpha=0.2) +
  scale_color_brewer(palette='Dark2', drop=FALSE) +
  ylab("Change in perplexity on PTB test data (%)") +
  ylim(NA, 2.0) +
  guides(linetype=F,
         color=F)+
  theme_bw(base_size=12) +
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```

```{r}
ggsave('../results/hundred_replay_cost_to_others.png', width=7, height=5)
```

```{r}
d %>%
  group_by(Approach) %>%
  summarize(max_delta=max(pct_test_delta), max_nw_delta = min(pct_delta))
```
```{r}
comp_d = plotting_d %>%
  select(new_word, Approach, pct_delta) %>%
  group_by(new_word) %>%
  spread(Approach, pct_delta) %>%
  ungroup() %>%
  mutate(delta_delta =`Optimizing\nfrom centroid` - Centroid, pct_delta_delta = (`Optimizing\nfrom centroid` - Centroid)/abs(Centroid), full_delta_delta=`Optimizing\nfrom centroid` - `Full training\nwith all words`)

comp_d %>%
  summarize(mean_delta_delta = mean(delta_delta, na.rm=T), min_delta_delta = min(delta_delta, na.rm=T), max_delta_delta = max(delta_delta, na.rm=T), mean_pct_delta_delta = mean(pct_delta_delta, na.rm=T))
```

```{r}
t.test(comp_d$full_delta_delta)
t.test(comp_d$delta_delta)
```

