---
title: "One Shot Word Learning Analysis"
output: html_notebook
---

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(stringr)
```

# Data Loading

```{r}
#words = c("explained", "bonuses", "explained_2nd", "bonuses_2nd") #, "bonuses", "entry", "rice", "rolled", "marketers", "immune", "cowboys", "borrow")
#num_train = 1:10
#approaches = c("opt", "opt_centroid", "centroid", "opt_zero")

#d = data.frame()
#for (word in words) {
#  for (n in num_train) {
#    for (a in approaches) {
#      filename = sprintf("../%s/%i_%s_results_log.csv", word, n, a)
#      this_d = read.csv(filename, header=F)
#      this_d = this_d %>% 
#        spread(V1, V2) %>%
#        mutate(new_word=word, num_train=n, approach=a)
#      d = rbind(d, this_d)
#      
#    }
#  }
#}
```

# Data manipulation
```{r}
#d = d %>% mutate(nw_delta = post_new_word_test_perp - pre_new_word_test_perp, ptb_test_delta=post_test_perp - pre_test_perp)
```

# Centroid vs. optimizing

```{r, warning=F, message=F}
#ggplot(data=d, aes(x=num_train, y=nw_delta, color=approach)) +
#  geom_line() +
#  facet_wrap(~ new_word) +
#  xlab("Number of training sentences") +
#  scale_x_continuous(breaks=1:10) +
#  ylab("Change in perplexity on new word dataset") +
#  theme_bw()
```

```{r}
#ggsave('../results/first_run_bonuses_vs_explained.png')
```

# Better comparison: 10 perms w/ fixed test


```{r}
words = c("explained", "bonuses", "strategist", "marketers") 
num_train = 1:10
perms = 1:10
approaches = c("opt", "opt_centroid", "centroid", "opt_zero")

d = data.frame()
withword_d = data.frame()
for (word in words) {
  for (perm in perms) {
    for (n in num_train) {
      for (a in approaches) {
        filename = sprintf("../result_data/%s_perm%i_train_logs/%s/%i_%s_results_log.csv", word, perm, word, n, a)
        if (!file.exists(filename)) {
          next
        }
        this_d = read.csv(filename, header=F)
        this_d = this_d %>% 
          spread(V1, V2) %>%
          mutate(new_word=word, perm=perm, num_train=n, approach=a)
        d = bind_rows(d, this_d)
        
      }
    }
  }
  filename = sprintf("../result_data/%s_withword_train_logs/%s/_results_log.csv", word, word)
  if (!file.exists(filename)) {
    next
  }
  this_d2 = read.csv(filename, header=F)
  this_d2 = this_d2 %>% 
    spread(V1, V2) %>%
    mutate(new_word=word) %>%
    select(-post_new_word_test_perp) %>%
    rename(post_withword_test_perp = pre_new_word_test_perp) %>%
    mutate(withoutword_test_perp=head(this_d$pre_new_word_test_perp, n=1))
  withword_d = bind_rows(withword_d, this_d2)
}

```

# Data manipulation
```{r}
d = d %>% 
  mutate(nw_delta = post_new_word_test_perp - pre_new_word_test_perp, pct_delta=100*nw_delta/pre_new_word_test_perp, perm=factor(perm), train_with_word=F) %>%
  mutate(approach=factor(approach, 
                         levels=c("centroid", "opt", "opt_centroid", "opt_zero", "train_with_word"), 
                         labels=c("Centroid", "Optimizing from current", "Optimizing from centroid", "Optimizing from zero", "Full training with the word")))
withword_d = withword_d %>% mutate(nw_delta = post_withword_test_perp - withoutword_test_perp, pct_delta=100*nw_delta/withoutword_test_perp)
```

```{r}
number_of_new_words = length(words)
withword_d = withword_d[rep(1:number_of_new_words, each=10),]
withword_d = withword_d %>%
  mutate(num_train=rep(1:10, number_of_new_words), approach='Full training with the word', train_with_word=T) %>%
  select(num_train, approach, new_word, nw_delta, pct_delta, train_with_word)
avg_d = d %>% 
  group_by(num_train, approach, new_word, train_with_word) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta=mean(pct_delta)) %>% 
  ungroup() %>% 
  rbind(., withword_d) %>%
  mutate(approach=factor(approach, 
                         levels=c("Centroid", "Optimizing from current", "Optimizing from centroid", "Optimizing from zero", "Full training with the word"), 
                         labels=c("Centroid", "Optimizing from current", "Optimizing from centroid", "Optimizing from zero", "Full training with the word")))
```

# Approach comparisons

```{r, echo=FALSE, message=F}
ggplot() +
  geom_line(data=avg_d, aes(x=num_train, y=pct_delta, color=approach, linetype=train_with_word), size=1) +
  geom_line(data=d, aes(x=num_train,y=pct_delta, color=approach, group=interaction(approach, perm)), alpha=0.25) +
  facet_wrap(~ new_word) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=1:10) +
  scale_color_brewer(palette='Dark2') +
  ylab("Change in perplexity on new word test data (%)") +
  guides(linetype=F) +
  theme_bw(base_size=12) +
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```
```{r}
ggsave('../results/10perms_delta_perplexity.png', width=10, height=7)
```

```{r}
noword_withword_d = withword_d %>%
  group_by(num_train, approach, train_with_word) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta=mean(pct_delta)) %>% 
  ungroup()
noword_d = d %>% 
  group_by(num_train, approach, train_with_word) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta=mean(pct_delta)) %>% 
  ungroup() %>%
  bind_rows(., noword_withword_d) %>%
  mutate(approach=factor(approach, 
                         levels=c("Centroid", "Optimizing from current", "Optimizing from centroid", "Optimizing from zero", "Full training with the word"), 
                         labels=c("Centroid", "Optimizing from current", "Optimizing from centroid", "Optimizing from zero", "Full training with the word")))
```

```{r, echo=FALSE, message=F}
ggplot() +
  geom_line(data=noword_d, aes(x=num_train, y=pct_delta, color=approach, linetype=train_with_word), size=1) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=1:10) +
  scale_color_brewer(palette='Dark2') +
  ylab("Change in perplexity on new word test data (%)") +
  guides(linetype=F) +
  theme_bw(base_size=12) +
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```
```{r}
ggsave('../results/10perms_delta_perplexity_summarized.png', width=10, height=7)
```
# Embeddings


(moved to python for efficiency)
```{r}
#words = c("explained", "bonuses") 
#num_train = 1:10
#perms = 1:10
#approaches = c("opt_centroid", "centroid", "opt_zero")

#d_emb = data.frame()
#for (word in words) {
#  for (a in approaches) {
#    for (perm in perms) {
#      for (n in num_train) {
#      
#        filename = sprintf("../result_data/%s_perm%i_train_logs/%s/embedding/num%i_%s_embedding_%s.csv", word, perm, word, n, a, a)
#        this_d = read.csv(filename, header=F)
#        this_d = this_d %>% 
#          mutate(index=1:1500) %>%
#          spread(index, V1) %>%
#          mutate(new_word=word, perm=perm, num_train=n, approach=a)
#        d_emb = rbind(d_emb, this_d)
#      }
#    }
#  }
#}
```


```{r}
#library(proxy)
```


```{r}
#q = simil(d_emb %>% select(-c(new_word, perm, num_train, approach)), upper=T, by_rows=T)
#image(as.matrix(q))
```


(moved to python for efficiency)
```{r}
#filename = sprintf("../result_data/pre_embeddings/%s/embedding_pre_full.csv", 'bonuses')
#full_pre_emb = read.csv(filename, header=F)
```
```{r}
#centroid = full_pre_emb %>% summarize_all(mean)
```





# Embeddings for real


```{r}
approaches = c("centroid", "opt", "opt_centroid", "opt_zero")

embedding_d = data.frame()
softmax_weight_d = data.frame()
this_d = read.csv('intermediate_data/emb_other_simils.csv', header=F)
this_d = this_d %>% 
  mutate(type='Other words') %>%
  rename(euclidean_distance=V1)
embedding_d = rbind(embedding_d, this_d)
this_d = read.csv('intermediate_data/smw_other_simils.csv', header=F)
this_d = this_d %>% 
  mutate(type='Other words') %>%
  rename(euclidean_distance=V1)
softmax_weight_d = rbind(softmax_weight_d, this_d)
for (a in 1:4) {
  for (b in a:4) {
    this_type = sprintf('%s vs. %s', approaches[a], approaches[b])
    this_d = read.csv(sprintf('intermediate_data/emb_%s_%s_simils.csv', approaches[a], approaches[b]), header=F)
    this_d = this_d %>% 
      mutate(type=this_type) %>%
      rename(euclidean_distance=V1)
    embedding_d = rbind(embedding_d, this_d)
    this_d = read.csv(sprintf('intermediate_data/smw_%s_%s_simils.csv', approaches[a], approaches[b]), header=F)
    this_d = this_d %>% 
      mutate(type=this_type) %>%
      rename(euclidean_distance=V1)
    softmax_weight_d = rbind(softmax_weight_d, this_d)
  }
}
```


```{r}
ggplot(data=embedding_d, aes(x=type, y=euclidean_distance, fill=type)) +
  geom_violin() +
  guides(fill=F) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggsave('../results/emb_distances_violin.png')


ggplot(data=softmax_weight_d, aes(x=type, y=euclidean_distance, fill=type)) +
  geom_violin() +
  guides(fill=F) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
ggsave('../results/smw_distances_violin.png')
```



# Optimizing only input or output embeddings

```{r}
words = c("explained", "bonuses", "strategist", "marketers") 
num_train = c(1, 10)
perms = 1:10
approaches = c("opt_centroid", "centroid")
skips = c("emb","sm")

skip_d = data.frame()
for (word in words) {
  for (perm in perms) {
    for (skipping in skips) {
      for (n in num_train) {
        for (a in approaches) {
          filename = sprintf("../result_data/%s_perm%i_skipping_%s_train_logs/%s/%i_%s_results_log.csv", word, perm, skipping, word, n, a)
          if (!file.exists(filename)){
            next
          }
          this_d = read.csv(filename, header=F)
          this_d = this_d %>% 
            spread(V1, V2) %>%
            mutate(new_word=word, perm=perm, num_train=n, approach=a, skipping=skipping)
          skip_d = bind_rows(skip_d, this_d)
        }
      }
    }
  }
}
```

```{r}
skip_d = skip_d %>% mutate(nw_delta = post_new_word_test_perp - pre_new_word_test_perp,
                           pct_delta = 100 * nw_delta / pre_new_word_test_perp,
                           perm=factor(perm),
                           optimizing=ifelse(skipping=="None", "Both", ifelse(skipping == "sm", "Input Embedding", "Output Embedding")),
                           approach=factor(approach, 
                                           levels=c("centroid", "opt", "opt_centroid", "opt_zero", "train_with_word"), 
                                           labels=c("Centroid", "Optimizing from current", "Optimizing from centroid", "Optimizing from zero", "Full training with the word")))
```

```{r}
# combine with subset of full training data that matches
filtered_d = d %>% 
  filter(num_train %in% c(1, 10), 
         approach %in% c("Centroid", "Optimizing from centroid")) %>%
  mutate(skipping='None', optimizing='Both') %>%
  select(-train_with_word)
skip_d = rbind(filtered_d, skip_d)
skip_d = skip_d %>%
  mutate(optimizing=factor(optimizing, levels=c("Input Embedding", "Output Embedding", "Both"))) %>%
  mutate(approach=factor(approach, 
                         levels=c("Centroid", "Optimizing from current", "Optimizing from centroid", "Optimizing from zero", "Full training with the word"), 
                         labels=c("Centroid", "Optimizing from current", "Optimizing from centroid", "Optimizing from zero", "Full training with the word")))
```

```{r}
avg_skip_d = skip_d %>% 
  group_by(num_train, approach, new_word, optimizing) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta = mean(pct_delta)) %>% 
  ungroup()
```

# Approach comparisons

```{r, echo=FALSE, message=F}
ggplot() +
  geom_line(data=avg_skip_d, aes(x=num_train, y=pct_delta, color=optimizing), size=1) +
  geom_line(data=skip_d, aes(x=num_train, y=pct_delta, color=optimizing, group=interaction(optimizing, perm)), alpha=0.25) +
  facet_grid(approach ~ new_word) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=c(1,10)) +
  scale_color_brewer(palette='Dark2') +
  ylab("Change in perplexity on new word test data (%)") +
  theme_bw(base_size=12)
```

```{r}
ggsave('../results/skipping_by_word.png', width=10, height=7)
```

```{r}
noword_avg_skip_d = skip_d %>% 
  group_by(num_train, approach, optimizing) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta = mean(pct_delta)) %>% 
  ungroup()
```

```{r}
ggplot() +
  geom_line(data=noword_avg_skip_d, aes(x=num_train, y=pct_delta, color=optimizing), size=1) +
  facet_grid(~ approach) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=c(1,10)) +
  scale_color_brewer(palette='Dark2') +
  ylab("Change in perplexity on new word test data (%)") +
  theme_bw(base_size=12)
```

```{r}
ggsave('../results/skipping_summarized.png')
```


# Round 2


```{r}
words = c("borrow", "cowboys", "immune", "rice") 
num_train = 1:10
perms = 1:10
approaches = c("opt_centroid", "centroid")

d = data.frame()
withword_d = data.frame()
for (word in words) {
  for (perm in perms) {
    for (n in num_train) {
      for (a in approaches) {
        filename = sprintf("../result_data_3/%s_perm%i_train_logs/%s/%i_%s_results_log.csv", word, perm, word, n, a)
        if (!file.exists(filename)) {
          next
        }
        this_d = read.csv(filename, header=F)
        this_d = this_d %>% 
          spread(V1, V2) %>%
          mutate(new_word=word, perm=perm, num_train=n, approach=a)
        d = bind_rows(d, this_d)
        
      }
    }
  }
  filename = sprintf("../result_data_3/%s_withword_train_logs/%s/_results_log.csv", word, word)
  if (!file.exists(filename)) {
    next
  }
  this_d2 = read.csv(filename, header=F)
  this_d2 = this_d2 %>% 
    spread(V1, V2) %>%
    mutate(new_word=word) %>%
    select(-post_new_word_test_perp) %>%
    rename(post_withword_test_perp = pre_new_word_test_perp) %>%
    mutate(withoutword_test_perp=head(this_d$pre_new_word_test_perp, n=1))
  withword_d = bind_rows(withword_d, this_d2)
}

```

# Data manipulation
```{r}
d = d %>% 
  mutate(nw_delta = post_new_word_test_perp - pre_new_word_test_perp, pct_delta=100*nw_delta/pre_new_word_test_perp, perm=factor(perm), train_with_word=F) %>%
  mutate(approach=factor(approach, 
                         levels=c("centroid", "opt_centroid", "train_with_word"), 
                         labels=c("Centroid", "Optimizing from centroid", "Full training with the word")))
withword_d = withword_d %>% mutate(nw_delta = post_withword_test_perp - withoutword_test_perp, pct_delta=100*nw_delta/withoutword_test_perp)
```

```{r}
number_of_new_words = length(words)
withword_d = withword_d[rep(1:number_of_new_words, each=10),]
withword_d = withword_d %>%
  mutate(num_train=rep(1:10, number_of_new_words), approach='Full training with the word', train_with_word=T) %>%
  select(num_train, approach, new_word, nw_delta, pct_delta, train_with_word)
avg_d = d %>% 
  group_by(num_train, approach, new_word, train_with_word) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta=mean(pct_delta)) %>% 
  ungroup() %>% 
  rbind(., withword_d) %>%
  mutate(approach=factor(approach, 
                         levels=c("Centroid", "Optimizing from centroid", "Full training with the word"), 
                         labels=c("Centroid", "Optimizing from centroid", "Full training with the word")))
```

# Approach comparisons

```{r, echo=FALSE, message=F}
ggplot() +
  geom_line(data=avg_d, aes(x=num_train, y=pct_delta, color=approach, linetype=train_with_word), size=1) +
  geom_line(data=d, aes(x=num_train,y=pct_delta, color=approach, group=interaction(approach, perm)), alpha=0.25) +
  facet_wrap(~ new_word) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=1:10) +
  scale_color_brewer(palette='Dark2') +
  ylab("Change in perplexity on new word test data (%)") +
  guides(linetype=F) +
  theme_bw(base_size=12) +
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```
```{r}
ggsave('../results/10perms_delta_perplexity.png', width=10, height=7)
```

```{r}
noword_withword_d = withword_d %>%
  group_by(num_train, approach, train_with_word) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta=mean(pct_delta)) %>% 
  ungroup()
noword_d = d %>% 
  group_by(num_train, approach, train_with_word) %>% 
  summarize(nw_delta = mean(nw_delta), pct_delta=mean(pct_delta)) %>% 
  ungroup() %>%
  bind_rows(., noword_withword_d) %>%
  mutate(approach=factor(approach, 
                         levels=c("Centroid", "Optimizing from current", "Optimizing from centroid", "Optimizing from zero", "Full training with the word"), 
                         labels=c("Centroid", "Optimizing from current", "Optimizing from centroid", "Optimizing from zero", "Full training with the word")))
```

```{r, echo=FALSE, message=F}
ggplot() +
  geom_line(data=noword_d, aes(x=num_train, y=pct_delta, color=approach, linetype=train_with_word), size=1) +
  xlab("Number of training sentences") +
  scale_x_continuous(breaks=1:10) +
  scale_color_brewer(palette='Dark2') +
  ylab("Change in perplexity on new word test data (%)") +
  guides(linetype=F) +
  theme_bw(base_size=12) +
  theme(panel.grid.minor=element_blank(), panel.grid.major=element_blank())
```
```{r}
ggsave('../results/10perms_delta_perplexity_summarized.png', width=10, height=7)
```
