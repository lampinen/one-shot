\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2017
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2017}

\usepackage[final]{nips_2017}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2017}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}

\title{Jabberwocky: One-shot and few-shot learning of word embeddings}

\author{
  Andrew K. Lampinen\\
  Department of Psychology\\
  Stanford University\\
  Stanford, CA 94305 \\
  \texttt{lampinen@stanford.edu} \\
  \And
  James L. McClelland\\
  Department of Psychology\\
  Stanford University\\
  Stanford, CA 94305 \\
  \texttt{mcclelland@stanford.edu} \\
}

\begin{document}

\maketitle

\begin{abstract}
Standard deep learning systems require thousands or millions of examples to learn a concept, and cannot integrate new concepts easily. By contrast, humans have an incredible ability to do one-shot or few-shot learning. For instance, from just hearing a word used in a sentence, humans can infer a great deal about it, by leveraging what the syntax and semantics of the surrounding words tells us. Here, we highlight a simple technique by which deep recurrent networks can similarly exploit their prior knowledge to learn a useful representation for a new word from little data. This could allow machine learning systems to learn continually from new words they encounter, and could also provide a model for human rapid word learning. 
\end{abstract}

\section{Introduction}
Humans are often able to infer approximate meanings of new words from context. For example, consider the following stanza from the poem ``Jabberwocky'' by Lewis Carroll: 
\begin{quote}
\centering
\textit{
He took his vorpal sword in hand:\\
Long time the manxome foe he soughtâ€”\\
So rested he by the Tumtum tree,\\
And stood awhile in thought.}
\end{quote}
Despite the fact that there are several nonsense words, we can follow the narrative of the poem and understand approximately what many of the words mean by how they relate other words. This a vital skill for interacting with the world -- we constantly need to learn new words and ideas. More generally, humans are often able to gracefully accomodate situations that differ radically from what they have seen before.\par 
By contrast, standard deep learning systems require much more data than humans to learn a concept or task, and sometimes generalize poorly \cite{Lake2016}. How can deep learning systems build on their prior knowledge to learn effectively from a few pieces of information? In this paper, we explore this issue in the specific context of creating a useful representation for a new word based on its context. \par
\subsection{Background}
Continuous representations of words have proven to be very effective in recent years \cite[e.g.]{Mikolov2013, Pennington2014}. These approaches represent words as vectors in a space, which are learned from large corpuses of text data. Using these vectors, deep learning systems have achieved success on tasks ranging from natural language translation \cite[e.g.]{Wu2016} to question answering \cite[e.g.]{Santoro2017}. \par
However, these word vectors are typically trained on very large datasets, and there has been surprisingly little prior work on how to learn embeddings for new words once the system has been trained. \citet{Cotterell2016} proposed a method for incorporating morphological information into word embeddings that allows for limited generalization to new words (e.g. generalizing to unseen conjugations of a known verb). However, this is not a general system for learning representations for new words, and requires building in rather strong structural assumptions about the language and having appropriately labelled data to exploit them. \par
More recently \citet{Lazaridou2017} explored multi-modal word learning (similar to what children do when an adult points out a new object), and in the process suggested a simple heuristic for inferring a word vector from context: simply average together all the surrounding word vectors. This is sensible, since the surrounding words will likely occur in similar contexts. However, it ignores all syntactic information, by treating all the surrounding words identically, and it relies on the semantic information being linearly combinable between different word embeddings. Both of these factors will likely limit its performance. \par
Is there a way we can do better? A deep learning system which has been trained to perform a language task must have learned a great deal of semantic and syntactic structure which would be useful for inferring the meaning of a new word. However, this knowledge is opaquely encoded in its weights. Is there a way we can exploit this knowledge, like humans exploit their prior knowledge when learning about a new word? \par
\section{Approach}
We suggest that we actually already know how to update the representations of a network while accounting for its current knowledge and inferences -- this is precisely what backpropagation was invented for! Of course, we cannot simply train the whole network to accomodate this new word, this would lead to catastrophic interference. However, \citet{Rumelhart1993} showed that a simple network could be taught about a new input by freezing all its weights except for those connecting the new input to the first hidden layer, and optimizing these by gradient descent as usual. They showed that this resulted in the network making appropriate generalizations about the new input, and by design the training procedure does not interfere with the network's prior knowledge. They used this as a model for human concept learning (as have other authors, for example \citet{Rogers2004}). \par
We take inspiration from this work to guide our approach. To learn from one sentence (or a few) containing a new word, we freeze all the weights in the network except those representing the new word (in a complex NLP system, there may be more than one such set of weights, for example the model we evaluate has distinct input and output embeddings for each word). We then use stochastic gradient descent (\(\eta = 0.01\)) to update the weights for the new word using 100 epochs of training over the sentence(s) containing it. \par
Of course, there are a variety of possible initializations for the embeddings before optimizing. In this paper, we consider three possibilities: 
\begin{enumerate}
\item Beginning with the current embedding for the word (since the model has never seen the word, and thus has been trained to never produce it, this will likely be an embedding that is far from any outputs the network typically produces).
\item Beginning with a vector of zeros.
\item Beginning with the centroid of the other words in the sentence, which \citet{Lazaridou2017} suggested was a useful estimate of an appropriate embedding.
\end{enumerate}
We compare this to two baselines:
\begin{enumerate}
\item The centroid of the embeddings for the other words in the sentence, as in \citet{Lazaridou2017}. 
\item Training the model with the 10 training sentences included in the corpus from the beginning (i.e. the ``standard'' deep-learning approach).
\end{enumerate}
\subsection{Task, Model, and Approach}
The framework we have described for updating embeddings could be applied very generally, but for the sake of this paper we ground it in a simple task: predicting the next word of a sentence based on the previous words, on the Penn Treebank dataset \citep{Marcus1993}. Specifically, we will use the (large) model architecture and approach of \citet{Zaremba2014a}. \par
Of course, human language understanding is much more complex than just prediction, and grounding language in situations and goals is likely important for achieving deeper understanding of language \citep{Gauthier2016}. More recent work has begun to do this \citep[e.g]{Hermann2017}, and it's likely that our approach would be more effective in settings like these. The ability of humans to make rich inferences about text stems from the richness of our knowledge. However, for simplicity, we have chosen to first demonstrate it on the prediction task. \par 
In order to test our one-shot word-learning algorithm on the Penn Treebank, we chose a word which appeared only 20 times in the training set. We removed the sentences containing this word and then trained the model with the remaining sentences for 55 epochs using the learning rate decay strategy of \citet{Zaremba2014a}. Because the PTB dataset contains over 40,000 sentences, the 20 missing ones had essentially no effect on the networks overall performance. We then split the 20 sentences containing the new word into 10 train and 10 test, and tried training on 1 - 10 of them in 10 different permutations (via a balanced Latin square \citep{Campbell1980}, which ensures that each sentence was used for one-shot learning once, and enforces diversity in the multi-shot learning examples). 
\section{Results}
\begin{figure}
\centering
\includegraphics[width=\textwidth]{../../results/10perms_delta_perplexity.png}
\caption{Percent change in perplexity on 10 test sentences containing new word, plotted vs. the number of training sentences, across four different words, comparing optimizing from three different starting points to centroid and training with the word baselines. Averages across 10 permutations are shown in the dark lines, the individual results are shown in light lines. (Note that the full training with the word was only run once, with a single permutation of all 10 training sentences.)}
\label{main_results_1}
\end{figure}
We first evaluated our approach on the words ``bonuses,'' ``explained,'' ``marketers,'' and ``strategist,'' either initializing from the current embedding for the word (after never seeing it), the zero vector, or the centroid of the surrounding words, and compared to the baselines of just taking the centroid of the surrounding words and full training with the words, see Fig. \ref{main_results_1}. Optimizing from the centroid was clearly the best approach, it outperforms all other approaches for learning a new word for all datasets, including the centroid approach \citet{Lazaridou2017}, and even outperforms full training with the word in three of the four cases (however, this likely comes with a tradeoff, see below). The optimizing approaches are strongly affected by embedding initialization with few training sentences (e.g. one-shot learning), but by 10 sentences they all perform quite similarly. \par
\begin{figure}
\centering
\includegraphics[width=\textwidth]{../../results/10perms2_delta_perplexity.png}
\caption{Percent change in perplexity on 10 test sentences containing new word, plotted vs. the number of training sentences, across four different words, comparing optimizing from the centroid to just taking the centroid and training with the word baselines.}
\label{main_results_2}
\end{figure}
Next, we replicated these findings with four new words (``borrow,'' ``cowboys'', ``immune,'' and ``rice''), see Fig. \ref{main_results_2}. 


\begin{figure}
\centering
\includegraphics[width=\textwidth]{../../results/skipping_by_word.png}
\caption{Comparing optimizing the input embedding, output embedding, or both -- where is the magic happening?}
\label{skipping_results}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=\textwidth]{../../results/10perms2_cost_to_others.png}
\caption{Unfortunately this interferes with performance on other words}
\label{interference}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=\textwidth]{../../results/10perms5_replay_cost_to_others.png}
\caption{This interference can be substantially ameliorated by using a small replay buffer}
\label{ameliorating_interference}
\end{figure}

\section{Discussion}

\section{Conclusions}
We have presented a technique for doing one- or few-shot learning of word embeddings from text data. This technique could allow natural language systems to adapt more flexibily to a changing world, as humans do. It could also provide a model for human learning. 

\bibliographystyle{apalike}
\bibliography{one_shot_words}

\end{document}
